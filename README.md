# Synthetic Data Generation

A simplified Distilabel-inspired pipeline for synthetic dataset creation using pandas DataFrames and local Ollama models.

## ğŸš€ Quick Start

```bash
# 1. Clone/create the project
cd synthetic_data_generation

# 2. Install dependencies
pip install -e .

# 3. Make sure Ollama is running
ollama serve

# 4. Pull a model (if not already done)
ollama pull llama3.2

# 5. Run example
python examples/instruction_pipeline.py

# 6. Run tests
pytest tests/ -v

# 7. Clear cache
python scripts/clear_cache.py
```

## ğŸ“– Features

- ğŸ¼ **Native pandas DataFrame support** - Work with familiar data structures
- ğŸ¦™ **Ollama local model integration** - Run LLMs locally without API costs
- ğŸ”„ **Step-based processing architecture** - Modular and extensible design
- ğŸ’¾ **Automatic caching** - Speed up iterations with intelligent caching
- ğŸ” **Batch processing** - Efficient processing of large datasets
- ğŸ› ï¸ **Easy to extend** - Create custom steps with simple API
- ğŸ”’ **Robust error handling** - Continue processing even when individual rows fail
- ğŸ“Š **Rich logging** - Track pipeline execution with detailed logs

## ğŸ—ï¸ Architecture

```
SimplePipeline
â”œâ”€â”€ LoadDataFrame (load data)
â”œâ”€â”€ FilterRows (filter data)
â”œâ”€â”€ SortRows (sort data)
â”œâ”€â”€ SampleRows (sample data)
â”œâ”€â”€ OllamaLLMStep (generate with LLM)
â”œâ”€â”€ RobustOllamaStep (generate with error handling)
â”œâ”€â”€ AddColumn (transform)
â””â”€â”€ KeepColumns (select columns)
```

## ğŸ“š Examples

### Basic Pipeline

```python
import pandas as pd
from simple_pipeline import SimplePipeline
from simple_pipeline.steps import LoadDataFrame, OllamaLLMStep

# Create data
df = pd.DataFrame({
    'topic': ['Python', 'Machine Learning', 'Web Development']
})

# Create pipeline
pipeline = SimplePipeline(name="basic-example")

# Add steps
pipeline.add_step(LoadDataFrame(name="load", df=df))
pipeline.add_step(OllamaLLMStep(
    name="explain",
    model_name="llama3.2",
    prompt_column="topic",
    output_column="explanation",
    batch_size=3
))

# Run
result = pipeline.run()
print(result)
```

### Advanced Pipeline with Transformations

```python
from simple_pipeline.steps import FilterRows, SortRows, RobustOllamaStep

pipeline = SimplePipeline(name="advanced")

# Filter, sort, and generate
pipeline.add_step(LoadDataFrame(name="load", df=data))
pipeline.add_step(FilterRows(
    name="filter",
    filter_column="priority",
    condition="> 5"
))
pipeline.add_step(SortRows(name="sort", by="priority", ascending=False))
pipeline.add_step(RobustOllamaStep(
    name="generate",
    model_name="llama3.2",
    prompt_column="topic",
    output_column="content",
    save_failures=True,  # Save failed rows
    continue_on_error=True  # Don't stop on errors
))

result = pipeline.run(use_cache=True)
```

### Using the >> Operator

```python
# Chain steps with >> for cleaner syntax
pipeline = SimplePipeline(name="chain")

(pipeline
    >> LoadDataFrame(name="load", df=data)
    >> FilterRows(name="filter", filter_func=lambda r: r['score'] > 5)
    >> OllamaLLMStep(name="generate", model_name="llama3.2", ...)
    >> KeepColumns(name="keep", columns=["topic", "generation"])
)

result = pipeline.run()
```

## ğŸ”§ Available Steps

### Data Loading

- **LoadDataFrame**: Load data from DataFrame or CSV

### Data Transformation

- **FilterRows**: Filter rows by condition or function
- **SortRows**: Sort by one or more columns
- **SampleRows**: Take random sample (n rows or fraction)
- **AddColumn**: Add computed column
- **KeepColumns**: Select specific columns

### LLM Generation

- **OllamaLLMStep**: Generate text with Ollama models
- **RobustOllamaStep**: Generate with error handling and metrics

## ğŸ¨ Creating Custom Steps

```python
from simple_pipeline.base_step import BaseStep
import pandas as pd

class MyCustomStep(BaseStep):
    def __init__(self, name: str, param: str, **kwargs):
        super().__init__(name, **kwargs)
        self.param = param

    @property
    def inputs(self):
        return ["input_column"]

    @property
    def outputs(self):
        return ["output_column"]

    def process(self, df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        df["output_column"] = df["input_column"].apply(
            lambda x: self.transform(x)
        )
        return df

    def transform(self, value):
        # Your custom logic here
        return value.upper()
```

## ğŸ“Š Caching

Caching is automatic and based on:

- Step configuration
- Input data hash
- Step name and parameters

```python
# Use cache (default)
result = pipeline.run(use_cache=True)

# Skip cache
result = pipeline.run(use_cache=False)

# Clear cache
pipeline.clear_cache()
```

## ğŸ› Error Handling

Use `RobustOllamaStep` for production pipelines:

```python
robust_step = RobustOllamaStep(
    name="generate",
    model_name="llama3.2",
    prompt_column="input",
    output_column="output",
    save_failures=True,  # Save failed rows to CSV
    failure_dir="./failures",  # Where to save failures
    continue_on_error=True,  # Don't stop on errors
    max_retries=3  # Retry failed generations
)

result = pipeline.run()

# Check metrics
print(f"Success rate: {robust_step.success_count} / {robust_step.success_count + robust_step.failure_count}")

# Get failure summary
summary = robust_step.get_failure_summary()
print(summary)
```

## ğŸ“ Logging

Configure logging level:

```python
pipeline = SimplePipeline(
    name="my-pipeline",
    log_level="DEBUG"  # DEBUG, INFO, WARNING, ERROR
)
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_pipeline.py -v

# Run with coverage
pytest tests/ --cov=simple_pipeline
```

## ğŸ“ Project Structure

```
synthetic_data_generation/
â”œâ”€â”€ simple_pipeline/           # Core library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_step.py          # Base step class
â”‚   â”œâ”€â”€ pipeline.py           # Pipeline orchestrator
â”‚   â”œâ”€â”€ steps/                # Built-in steps
â”‚   â”‚   â”œâ”€â”€ load_dataframe.py
â”‚   â”‚   â”œâ”€â”€ ollama_step.py
â”‚   â”‚   â”œâ”€â”€ robust_ollama.py
â”‚   â”‚   â”œâ”€â”€ filter_rows.py
â”‚   â”‚   â”œâ”€â”€ sort_rows.py
â”‚   â”‚   â”œâ”€â”€ sample_rows.py
â”‚   â”‚   â”œâ”€â”€ keep_columns.py
â”‚   â”‚   â””â”€â”€ add_column.py
â”‚   â””â”€â”€ utils/                # Utilities
â”‚       â”œâ”€â”€ cache.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ batching.py
â”œâ”€â”€ examples/                 # Example pipelines
â”‚   â”œâ”€â”€ instruction_pipeline.py
â”‚   â”œâ”€â”€ model_comparison.py
â”‚   â””â”€â”€ advanced_pipeline.py
â”œâ”€â”€ notebooks/               # Jupyter notebooks
â”‚   â””â”€â”€ demo.ipynb
â”œâ”€â”€ tests/                   # Test suite
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_steps.py
â”œâ”€â”€ scripts/                 # CLI scripts
â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â””â”€â”€ clear_cache.py
â””â”€â”€ data/                    # Data directory
    â””â”€â”€ .gitkeep
```

## ğŸ¤ Contributing

Contributions are welcome! To add a new step:

1. Create a new file in `simple_pipeline/steps/`
2. Inherit from `BaseStep`
3. Implement `inputs`, `outputs`, and `process()`
4. Add to `simple_pipeline/steps/__init__.py`
5. Write tests in `tests/`

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

Inspired by [Distilabel](https://github.com/argilla-io/distilabel) by Argilla.

## ğŸ“ Support

- Issues: [GitHub Issues](https://github.com/alvaldes/synthetic_data_generation/issues)
- Documentation: See `examples/` and `notebooks/`

## ğŸ¯ Roadmap

- [ ] Support for async Ollama calls
- [ ] Multiprocessing for parallel step execution
- [ ] More built-in steps (GroupBy, Merge, etc.)
- [ ] Web UI for pipeline monitoring
- [ ] Export to Hugging Face datasets
- [ ] Integration with other LLM providers
