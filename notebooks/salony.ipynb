{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e8be84",
   "metadata": {},
   "source": [
    "Este pipeline toma historias de usuario del dataset salony_train.csv y las descompone\n",
    "en tareas de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cffec7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "from simple_pipeline import SimplePipeline\n",
    "from simple_pipeline.steps import LoadDataFrame, OllamaLLMStep, OllamaJudgeStep, AddColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed41e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_generation_prompt(row: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Crea el prompt para generar tareas a partir de una historia de usuario del dataset Salony.\n",
    "    \n",
    "    Args:\n",
    "        row: Fila del DataFrame con la columna 'input' que contiene la historia\n",
    "    \n",
    "    Returns:\n",
    "        Prompt formateado\n",
    "    \"\"\"\n",
    "    user_story = row['input'].strip()\n",
    "    \n",
    "    prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides a user story.\n",
    "\n",
    "Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "Instruction:\n",
    "\n",
    "Break this user story into smaller development tasks to help the developers implement it efficiently. You can divide this user story into as many tasks as needed, depending on its complexity. Each task must be unique, actionable, and non-overlapping.\n",
    "\n",
    "Use the following format for the response:\n",
    "\n",
    "1. summary: ‚Äπtask summary 1‚Ä∫\n",
    "description: ‚Äπtask description 1‚Ä∫\n",
    "2. summary: ‚Äπtask summary 2‚Ä∫\n",
    "description: ‚Äπtask description 2‚Ä∫\n",
    "\n",
    "N. summary: ‚Äπtask summary N‚Ä∫\n",
    "description: ‚Äπtask description N‚Ä∫\n",
    "\n",
    "\n",
    "Input:\n",
    "\n",
    "{user_story}\n",
    "\n",
    "\n",
    "Response:\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0d27a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_salony_pipeline(\n",
    "    output_csv: str,\n",
    "    model_name: str = \"llama3.1:8b\",\n",
    "    judge_model_name: str = \"llama3.1:8b\", \n",
    "    batch_size: int = 2,\n",
    "    temperature: float = 0.3,\n",
    "    num_predict: int = 1000,\n",
    "    sample_size: int = None,\n",
    "    use_judge: bool = True,\n",
    "    judge_threshold: float = 35.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline de generaci√≥n de tareas para historias de usuario Salony.\n",
    "    \n",
    "    Args:\n",
    "        output_csv: Ruta donde guardar el resultado\n",
    "        model_name: Modelo de Ollama a usar para generaci√≥n de tareas\n",
    "        judge_model_name: Modelo de Ollama a usar para validaci√≥n (juez)\n",
    "        batch_size: N√∫mero de historias a procesar simult√°neamente\n",
    "        temperature: Temperatura para generaci√≥n\n",
    "        num_predict: Tokens m√°ximos a generar\n",
    "        sample_size: Si se especifica, procesa solo N historias (para pruebas)\n",
    "        use_judge: Si activar validaci√≥n con LLM juez\n",
    "        judge_threshold: Umbral de aprobaci√≥n del juez (0-50)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üöÄ SALONY USER STORIES TO TASKS PIPELINE\")\n",
    "    if use_judge:\n",
    "        print(\"üîç CON VALIDACI√ìN LLM JUEZ ACTIVADA\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Cargar datos - Usar ruta relativa desde el notebook\n",
    "    input_csv = Path(\"../data/salony_train.csv\")\n",
    "    print(f\"üì• Cargando datos desde: {input_csv}\")\n",
    "    \n",
    "    if not input_csv.exists():\n",
    "        raise FileNotFoundError(f\"No se encontr√≥ el archivo: {input_csv}\")\n",
    "    \n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Eliminar la primera columna si es un √≠ndice\n",
    "    if df.columns[0] == 'Unnamed: 0' or df.columns[0] == '':\n",
    "        df = df.iloc[:, 1:]\n",
    "    \n",
    "    print(f\"   ‚úì {len(df)} historias cargadas\")\n",
    "    \n",
    "    # Verificar columna 'input'\n",
    "    if 'input' not in df.columns:\n",
    "        raise ValueError(\"El CSV debe tener una columna 'input' con las historias de usuario\")\n",
    "    \n",
    "    # Aplicar sampling si se solicita\n",
    "    if sample_size:\n",
    "        df = df.head(sample_size)\n",
    "        print(f\"   ‚ÑπÔ∏è  Procesando solo {sample_size} historias (modo muestra)\")\n",
    "    \n",
    "    # Limpiar datos\n",
    "    df = df.dropna(subset=['input'])\n",
    "    df['input'] = df['input'].str.strip()\n",
    "    \n",
    "    # Crear pipeline\n",
    "    print(f\"\\n‚öôÔ∏è Configurando pipeline:\")\n",
    "    print(f\"   Modelo generador: {model_name}\")\n",
    "    if use_judge:\n",
    "        print(f\"   Modelo juez: {judge_model_name}\")\n",
    "        print(f\"   Umbral de aprobaci√≥n: {judge_threshold}/50\")\n",
    "    print(f\"   Batch size: {batch_size}\")\n",
    "    print(f\"   Temperature: {temperature}\")\n",
    "    print(f\"   Historias a procesar: {len(df)}\")\n",
    "    \n",
    "    pipeline = SimplePipeline(\n",
    "        name=\"salony-tasks-pipeline-with-judge\",\n",
    "        description=\"Pipeline para generar y validar tareas de desarrollo del dataset Salony\"\n",
    "    )\n",
    "    \n",
    "    # Paso 1: Cargar datos\n",
    "    pipeline.add_step(\n",
    "        LoadDataFrame(name=\"load\", df=df)\n",
    "    )\n",
    "    \n",
    "    # Paso 2: Agregar columna con nombre del modelo generador\n",
    "    pipeline.add_step(\n",
    "        AddColumn(\n",
    "            name=\"add_generator_model\",\n",
    "            input_columns=[],  # No necesita columnas de entrada\n",
    "            output_column=\"generator_model_name\",\n",
    "            func=lambda: model_name\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Paso 3: Generar tareas\n",
    "    pipeline.add_step(\n",
    "        OllamaLLMStep(\n",
    "            name=\"generate_tasks\",\n",
    "            model_name=model_name,\n",
    "            prompt_column=\"input\",\n",
    "            output_column=\"tasks\",\n",
    "            prompt_template=create_task_generation_prompt,\n",
    "            system_prompt=\"You are an expert software development lead who excels at breaking down user stories into clear, actionable development tasks.\",\n",
    "            batch_size=batch_size,\n",
    "            generation_kwargs={\n",
    "                \"temperature\": temperature,\n",
    "                \"num_predict\": num_predict\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Paso 4: Validar tareas con LLM juez (opcional)\n",
    "    if use_judge:\n",
    "        # Agregar columna con nombre del modelo juez\n",
    "        pipeline.add_step(\n",
    "            AddColumn(\n",
    "                name=\"add_judge_model\",\n",
    "                input_columns=[],  # No necesita columnas de entrada\n",
    "                output_column=\"judge_model_name\",\n",
    "                func=lambda: judge_model_name\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        pipeline.add_step(\n",
    "            OllamaJudgeStep(\n",
    "                name=\"validate_tasks\",\n",
    "                model_name=judge_model_name,\n",
    "                historia_usuario_column=\"input\",\n",
    "                tareas_generadas_column=\"tasks\",\n",
    "                approval_threshold=judge_threshold,\n",
    "                batch_size=max(1, batch_size // 2),  # Batch m√°s peque√±o para juez\n",
    "                generation_kwargs={\n",
    "                    \"temperature\": 0.2,  # Temperatura baja para juez m√°s consistente\n",
    "                    \"num_predict\": 800\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Ejecutar\n",
    "    print(f\"\\nüîÑ Procesando historias...\\n\")\n",
    "    result_df = pipeline.run(use_cache=False)\n",
    "    \n",
    "    # Guardar\n",
    "    print(f\"\\nüíæ Guardando resultados...\")\n",
    "    result_df.to_csv(output_csv, index=False)\n",
    "    print(f\"   ‚úì CSV guardado: {output_csv}\")\n",
    "    print(f\"   ‚úì {len(result_df)} historias procesadas\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas de validaci√≥n si se us√≥ juez\n",
    "    if use_judge and 'validacion_aprobado' in result_df.columns:\n",
    "        aprobadas = result_df['validacion_aprobado'].sum()\n",
    "        total = len(result_df)\n",
    "        print(f\"\\nüìä Estad√≠sticas de validaci√≥n:\")\n",
    "        print(f\"   ‚úÖ Aprobadas: {aprobadas}/{total} ({aprobadas/total*100:.1f}%)\")\n",
    "        print(f\"   ‚ùå Rechazadas: {total-aprobadas}/{total} ({(total-aprobadas)/total*100:.1f}%)\")\n",
    "        \n",
    "        if 'validacion_total' in result_df.columns:\n",
    "            avg_score = result_df['validacion_total'].mean()\n",
    "            print(f\"   üìà Puntuaci√≥n promedio: {avg_score:.1f}/50\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Mostrar ejemplo\n",
    "    print(\"üìã Ejemplo de resultado (primeras 2 filas):\\n\")\n",
    "    for idx, row in result_df.head(2).iterrows():\n",
    "        print(f\"üîπ Historia #{idx}:\")\n",
    "        print(f\"   Input: {row['input'][:100]}...\")\n",
    "        if 'tasks' in row and pd.notna(row['tasks']):\n",
    "            print(f\"   Tasks: {row['tasks'][:150]}...\")\n",
    "        if 'model_generador' in row:\n",
    "            print(f\"   Modelo generador: {row['model_generador']}\")\n",
    "        if use_judge and 'model_juez' in row:\n",
    "            print(f\"   Modelo juez: {row['model_juez']}\")\n",
    "        if use_judge and 'validacion_aprobado' in row:\n",
    "            status = \"‚úÖ APROBADO\" if row['validacion_aprobado'] else \"‚ùå RECHAZADO\"\n",
    "            print(f\"   Validaci√≥n: {status} (Score: {row.get('validacion_total', 'N/A')}/50)\")\n",
    "        print()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d16e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: load\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: add_generator_model\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: generate_tasks\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: add_judge_model\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: validate_tasks\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Starting pipeline: salony-tasks-pipeline-with-judge\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Number of steps: 5\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing generator step: load\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing step: add_generator_model\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO -   ‚úì Complete (3 rows, 2 columns)\n",
      "2025-11-11 12:41:07 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing step: generate_tasks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ SALONY USER STORIES TO TASKS PIPELINE\n",
      "üîç CON VALIDACI√ìN LLM JUEZ ACTIVADA\n",
      "================================================================================\n",
      "\n",
      "üì• Cargando datos desde: ../data/salony_train.csv\n",
      "   ‚úì 1999 historias cargadas\n",
      "   ‚ÑπÔ∏è  Procesando solo 3 historias (modo muestra)\n",
      "\n",
      "‚öôÔ∏è Configurando pipeline:\n",
      "   Modelo generador: llama3.1:8b\n",
      "   Modelo juez: llama3.1:8b\n",
      "   Umbral de aprobaci√≥n: 35.0/50\n",
      "   Batch size: 2\n",
      "   Temperature: 0.3\n",
      "   Historias a procesar: 3\n",
      "\n",
      "üîÑ Procesando historias...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing generate_tasks:   0%|          | 0/3 [00:00<?, ?it/s]2025-11-11 12:41:23 - OllamaLLMStep.generate_tasks - INFO - Generation for row 0: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch the user's transaction history from the database, including date, amount, and description.\n",
      "\n",
      "2. summary: Display Transaction History on User Interface\n",
      "description: Create a UI component to display the retrieved transaction history in a readable format, allowing users to scroll through their past transactions.\n",
      "\n",
      "3. summary: Implement Record-Keeping Functionality\n",
      "description: Develop a feature that allows users to mark specific transactions as \"recorded\" or \"archived,\" enabling them to easily identify and access important transactions later.\n",
      "\n",
      "4. summary: Store Recorded Transactions in Database\n",
      "description: Update the database schema to store recorded transactions separately from regular transaction history, ensuring easy retrieval of marked transactions.\n",
      "\n",
      "5. summary: Add Navigation for Transaction History\n",
      "description: Implement a clear navigation path on the user interface to direct users to their transaction history page, making it easily accessible and discoverable.\n",
      "\n",
      "6. summary: Handle Edge Cases and Error Handling\n",
      "description: Develop robust error handling and edge case scenarios for retrieving and displaying transaction history, including cases where data is missing or corrupted.\n",
      "\n",
      "7. summary: Integrate with Existing Authentication System\n",
      "description: Ensure that the new feature integrates seamlessly with the existing authentication system, requiring users to be logged in to access their transaction history.\n",
      "2025-11-11 12:41:33 - OllamaLLMStep.generate_tasks - INFO - Generation for row 1: 1. summary: Research and Document Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that will be supported by the system, including their corresponding Unicode characters, and document them for future reference.\n",
      "\n",
      "2. summary: Integrate Font Support for Greek Characters\n",
      "description: Update the application's font settings to include support for displaying Greek characters, ensuring compatibility with various operating systems and browsers.\n",
      "\n",
      "3. summary: Develop Input Method for Greek Symbols\n",
      "description: Design and implement an input method that allows researchers to easily insert Greek symbols into their logbook entries, such as a keyboard shortcut or a dedicated toolbar button.\n",
      "\n",
      "4. summary: Validate User Input for Greek Characters\n",
      "description: Implement validation logic to ensure that the application correctly handles user input containing Greek characters, including proper encoding and rendering.\n",
      "\n",
      "5. summary: Test Greek Character Support Across Various Platforms\n",
      "description: Conduct thorough testing on different operating systems, browsers, and devices to verify that Greek character support is consistent and functional across all environments.\n",
      "\n",
      "6. summary: Document User Interface Updates for Greek Symbol Input\n",
      "description: Update the application's user documentation and online help resources to include information on how to use the new Greek symbol input feature, including any relevant keyboard shortcuts or toolbar buttons.\n",
      "Processing generate_tasks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:26<00:13, 13.28s/it]2025-11-11 12:41:42 - OllamaLLMStep.generate_tasks - INFO - Generation for row 2: 1. summary: Identify Embargo Configuration\n",
      "description: Research and document the current embargo configuration for the DigitalRecords repository, including any existing rules or settings related to lifting embargoes.\n",
      "\n",
      "2. summary: Update Repository Settings\n",
      "description: Modify the repository settings to automatically lift embargoes on the specified release date, ensuring that access controls are updated accordingly.\n",
      "\n",
      "3. summary: Configure Access Controls\n",
      "description: Set up access controls for the DigitalRecords repository based on the configuration set on each item, so that access is granted or restricted according to the specified rules.\n",
      "\n",
      "4. summary: Test Embargo Configuration\n",
      "description: Verify that the updated embargo configuration and access controls are working correctly by testing various scenarios, including lifting embargoes and granting/denying access to items with different configurations.\n",
      "\n",
      "5. summary: Document Changes\n",
      "description: Update documentation and knowledge base articles to reflect changes made to the repository settings, including any new or modified rules related to lifting embargoes and setting access controls.\n",
      "Processing generate_tasks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:34<00:00, 11.63s/it]\n",
      "2025-11-11 12:41:42 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO -   ‚úì Complete (3 rows, 4 columns)\n",
      "2025-11-11 12:41:42 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing step: add_judge_model\n",
      "2025-11-11 12:41:42 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO -   ‚úì Complete (3 rows, 5 columns)\n",
      "2025-11-11 12:41:42 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing step: validate_tasks\n",
      "Validating validate_tasks:   0%|          | 0/3 [00:00<?, ?it/s]2025-11-11 12:42:00 - OllamaJudgeStep.validate_tasks - INFO - Validaci√≥n para fila 0: aprobado=True, total=44\n",
      "Validating validate_tasks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:18<00:36, 18.42s/it]2025-11-11 12:42:20 - OllamaJudgeStep.validate_tasks - INFO - Validaci√≥n para fila 1: aprobado=True, total=44\n",
      "Validating validate_tasks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:38<00:19, 19.41s/it]2025-11-11 12:42:40 - OllamaJudgeStep.validate_tasks - INFO - Validaci√≥n para fila 2: aprobado=True, total=44\n",
      "Validating validate_tasks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:58<00:00, 19.53s/it]\n",
      "2025-11-11 12:42:40 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO -   ‚úì Complete (3 rows, 14 columns)\n",
      "2025-11-11 12:42:40 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Pipeline execution complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Guardando resultados...\n",
      "   ‚úì CSV guardado: salony_tasks_with_validation.csv\n",
      "   ‚úì 3 historias procesadas\n",
      "\n",
      "üìä Estad√≠sticas de validaci√≥n:\n",
      "   ‚úÖ Aprobadas: 3/3 (100.0%)\n",
      "   ‚ùå Rechazadas: 0/3 (0.0%)\n",
      "   üìà Puntuaci√≥n promedio: 44.0/50\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "üìã Ejemplo de resultado (primeras 2 filas):\n",
      "\n",
      "üîπ Historia #0:\n",
      "   Input: As a user, I want to be able to check transaction history and keep a record of it, so that I can go ...\n",
      "   Tasks: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch the user's transaction history from the database, includin...\n",
      "   Validaci√≥n: ‚úÖ APROBADO (Score: 44/50)\n",
      "\n",
      "üîπ Historia #1:\n",
      "   Input: As a researcher, I want to have the ability to insert Greek symbols into my logbook entries....\n",
      "   Tasks: 1. summary: Research and Document Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that will be supported by the system, inclu...\n",
      "   Validaci√≥n: ‚úÖ APROBADO (Score: 44/50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Pipeline completo con validaci√≥n LLM juez\n",
    "result_df = run_salony_pipeline(\n",
    "    output_csv=\"salony_tasks_with_validation.csv\",\n",
    "    model_name=\"llama3.1:8b\",\n",
    "    judge_model_name=\"llama3.1:8b\", \n",
    "    batch_size=2,\n",
    "    temperature=0.3,\n",
    "    num_predict=1000,\n",
    "    sample_size=3,\n",
    "    use_judge=True,\n",
    "    judge_threshold=35.0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
