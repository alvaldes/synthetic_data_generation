{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e8be84",
   "metadata": {},
   "source": [
    "Este pipeline toma historias de usuario del dataset salony_train.csv y las descompone\n",
    "en tareas de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cffec7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "from simple_pipeline import SimplePipeline\n",
    "from simple_pipeline.steps import LoadDataFrame, OllamaLLMStep, OllamaJudgeStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed41e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_generation_prompt(row: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Crea el prompt para generar tareas a partir de una historia de usuario del dataset Salony.\n",
    "    \n",
    "    Args:\n",
    "        row: Fila del DataFrame con la columna 'input' que contiene la historia\n",
    "    \n",
    "    Returns:\n",
    "        Prompt formateado\n",
    "    \"\"\"\n",
    "    user_story = row['input'].strip()\n",
    "    \n",
    "    prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides a user story.\n",
    "\n",
    "Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "Instruction:\n",
    "\n",
    "Break this user story into smaller development tasks to help the developers implement it efficiently. You can divide this user story into as many tasks as needed, depending on its complexity. Each task must be unique, actionable, and non-overlapping.\n",
    "\n",
    "Use the following format for the response:\n",
    "\n",
    "1. summary: ‚Äπtask summary 1‚Ä∫\n",
    "description: ‚Äπtask description 1‚Ä∫\n",
    "2. summary: ‚Äπtask summary 2‚Ä∫\n",
    "description: ‚Äπtask description 2‚Ä∫\n",
    "\n",
    "N. summary: ‚Äπtask summary N‚Ä∫\n",
    "description: ‚Äπtask description N‚Ä∫\n",
    "\n",
    "\n",
    "Input:\n",
    "\n",
    "{user_story}\n",
    "\n",
    "\n",
    "Response:\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d27a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_salony_pipeline(\n",
    "    output_csv: str,\n",
    "    model_name: str = \"llama3.1:8b\",\n",
    "    judge_model_name: str = \"llama3.1:8b\", \n",
    "    batch_size: int = 2,\n",
    "    temperature: float = 0.3,\n",
    "    num_predict: int = 1000,\n",
    "    sample_size: int = None,\n",
    "    use_judge: bool = True,\n",
    "    judge_threshold: float = 35.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline de generaci√≥n de tareas para historias de usuario Salony.\n",
    "    \n",
    "    Args:\n",
    "        output_csv: Ruta donde guardar el resultado\n",
    "        model_name: Modelo de Ollama a usar para generaci√≥n de tareas\n",
    "        judge_model_name: Modelo de Ollama a usar para validaci√≥n (juez)\n",
    "        batch_size: N√∫mero de historias a procesar simult√°neamente\n",
    "        temperature: Temperatura para generaci√≥n\n",
    "        num_predict: Tokens m√°ximos a generar\n",
    "        sample_size: Si se especifica, procesa solo N historias (para pruebas)\n",
    "        use_judge: Si activar validaci√≥n con LLM juez\n",
    "        judge_threshold: Umbral de aprobaci√≥n del juez (0-50)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üöÄ SALONY USER STORIES TO TASKS PIPELINE\")\n",
    "    if use_judge:\n",
    "        print(\"üîç CON VALIDACI√ìN LLM JUEZ ACTIVADA\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Cargar datos - Usar ruta relativa desde el notebook\n",
    "    input_csv = Path(\"../data/salony_train.csv\")\n",
    "    print(f\"üì• Cargando datos desde: {input_csv}\")\n",
    "    \n",
    "    if not input_csv.exists():\n",
    "        raise FileNotFoundError(f\"No se encontr√≥ el archivo: {input_csv}\")\n",
    "    \n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Eliminar la primera columna si es un √≠ndice\n",
    "    if df.columns[0] == 'Unnamed: 0' or df.columns[0] == '':\n",
    "        df = df.iloc[:, 1:]\n",
    "    \n",
    "    print(f\"   ‚úì {len(df)} historias cargadas\")\n",
    "    \n",
    "    # Verificar columna 'input'\n",
    "    if 'input' not in df.columns:\n",
    "        raise ValueError(\"El CSV debe tener una columna 'input' con las historias de usuario\")\n",
    "    \n",
    "    # Aplicar sampling si se solicita\n",
    "    if sample_size:\n",
    "        df = df.head(sample_size)\n",
    "        print(f\"   ‚ÑπÔ∏è  Procesando solo {sample_size} historias (modo muestra)\")\n",
    "    \n",
    "    # Limpiar datos\n",
    "    df = df.dropna(subset=['input'])\n",
    "    df['input'] = df['input'].str.strip()\n",
    "    \n",
    "    # Crear pipeline\n",
    "    print(f\"\\n‚öôÔ∏è Configurando pipeline:\")\n",
    "    print(f\"   Modelo generador: {model_name}\")\n",
    "    if use_judge:\n",
    "        print(f\"   Modelo juez: {judge_model_name}\")\n",
    "        print(f\"   Umbral de aprobaci√≥n: {judge_threshold}/50\")\n",
    "    print(f\"   Batch size: {batch_size}\")\n",
    "    print(f\"   Temperature: {temperature}\")\n",
    "    print(f\"   Historias a procesar: {len(df)}\")\n",
    "    \n",
    "    pipeline = SimplePipeline(\n",
    "        name=\"salony-tasks-pipeline-with-judge\",\n",
    "        description=\"Pipeline para generar y validar tareas de desarrollo del dataset Salony\"\n",
    "    )\n",
    "    \n",
    "    # Paso 1: Cargar datos\n",
    "    pipeline.add_step(\n",
    "        LoadDataFrame(name=\"load\", df=df)\n",
    "    )\n",
    "    \n",
    "    # Paso 2: Generar tareas\n",
    "    pipeline.add_step(\n",
    "        OllamaLLMStep(\n",
    "            name=\"generate_tasks\",\n",
    "            model_name=model_name,\n",
    "            prompt_column=\"input\",\n",
    "            output_column=\"tasks\",\n",
    "            prompt_template=create_task_generation_prompt,\n",
    "            system_prompt=\"You are an expert software development lead who excels at breaking down user stories into clear, actionable development tasks.\",\n",
    "            batch_size=batch_size,\n",
    "            generation_kwargs={\n",
    "                \"temperature\": temperature,\n",
    "                \"num_predict\": num_predict\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Paso 3: Validar tareas con LLM juez (opcional)\n",
    "    if use_judge:\n",
    "        pipeline.add_step(\n",
    "            OllamaJudgeStep(\n",
    "                name=\"validate_tasks\",\n",
    "                model_name=judge_model_name,\n",
    "                historia_usuario_column=\"input\",\n",
    "                tareas_generadas_column=\"tasks\",\n",
    "                approval_threshold=judge_threshold,\n",
    "                batch_size=max(1, batch_size // 2),  # Batch m√°s peque√±o para juez\n",
    "                generation_kwargs={\n",
    "                    \"temperature\": 0.2,  # Temperatura baja para juez m√°s consistente\n",
    "                    \"num_predict\": 800\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Ejecutar\n",
    "    print(f\"\\nüîÑ Procesando historias...\\n\")\n",
    "    result_df = pipeline.run(use_cache=False)\n",
    "    \n",
    "    # Guardar\n",
    "    print(f\"\\nüíæ Guardando resultados...\")\n",
    "    result_df.to_csv(output_csv, index=False)\n",
    "    print(f\"   ‚úì CSV guardado: {output_csv}\")\n",
    "    print(f\"   ‚úì {len(result_df)} historias procesadas\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas de validaci√≥n si se us√≥ juez\n",
    "    if use_judge and 'validacion_aprobado' in result_df.columns:\n",
    "        aprobadas = result_df['validacion_aprobado'].sum()\n",
    "        total = len(result_df)\n",
    "        print(f\"\\nüìä Estad√≠sticas de validaci√≥n:\")\n",
    "        print(f\"   ‚úÖ Aprobadas: {aprobadas}/{total} ({aprobadas/total*100:.1f}%)\")\n",
    "        print(f\"   ‚ùå Rechazadas: {total-aprobadas}/{total} ({(total-aprobadas)/total*100:.1f}%)\")\n",
    "        \n",
    "        if 'validacion_total' in result_df.columns:\n",
    "            avg_score = result_df['validacion_total'].mean()\n",
    "            print(f\"   üìà Puntuaci√≥n promedio: {avg_score:.1f}/50\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Mostrar ejemplo\n",
    "    print(\"üìã Ejemplo de resultado (primeras 2 filas):\\n\")\n",
    "    for idx, row in result_df.head(2).iterrows():\n",
    "        print(f\"üîπ Historia #{idx}:\")\n",
    "        print(f\"   Input: {row['input'][:100]}...\")\n",
    "        if 'tasks' in row and pd.notna(row['tasks']):\n",
    "            print(f\"   Tasks: {row['tasks'][:150]}...\")\n",
    "        if use_judge and 'validacion_aprobado' in row:\n",
    "            status = \"‚úÖ APROBADO\" if row['validacion_aprobado'] else \"‚ùå RECHAZADO\"\n",
    "            print(f\"   Validaci√≥n: {status} (Score: {row.get('validacion_total', 'N/A')}/50)\")\n",
    "        print()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d16e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 12:21:49 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: load\n",
      "2025-11-11 12:21:49 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: generate_tasks\n",
      "2025-11-11 12:21:49 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Added step: validate_tasks\n",
      "2025-11-11 12:21:49 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Starting pipeline: salony-tasks-pipeline-with-judge\n",
      "2025-11-11 12:21:49 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Number of steps: 3\n",
      "2025-11-11 12:21:49 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing generator step: load\n",
      "2025-11-11 12:21:49 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing step: generate_tasks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ SALONY USER STORIES TO TASKS PIPELINE\n",
      "üîç CON VALIDACI√ìN LLM JUEZ ACTIVADA\n",
      "================================================================================\n",
      "\n",
      "üì• Cargando datos desde: ../data/salony_train.csv\n",
      "   ‚úì 1999 historias cargadas\n",
      "   ‚ÑπÔ∏è  Procesando solo 3 historias (modo muestra)\n",
      "\n",
      "‚öôÔ∏è Configurando pipeline:\n",
      "   Modelo generador: llama3.1:8b\n",
      "   Modelo juez: llama3.1:8b\n",
      "   Umbral de aprobaci√≥n: 35.0/50\n",
      "   Batch size: 2\n",
      "   Temperature: 0.3\n",
      "   Historias a procesar: 3\n",
      "\n",
      "üîÑ Procesando historias...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing generate_tasks:   0%|          | 0/3 [00:00<?, ?it/s]2025-11-11 12:22:03 - OllamaLLMStep.generate_tasks - INFO - Generation for row 0: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch transaction history data from the database, including date, amount, and description.\n",
      "\n",
      "2. summary: Display Transaction History on User Interface\n",
      "description: Create a user interface component (e.g., table or list) to display the retrieved transaction history data in a readable format.\n",
      "\n",
      "3. summary: Implement Record Keeping Functionality\n",
      "description: Develop a feature that allows users to mark specific transactions as recorded, and store this information in the database for future reference.\n",
      "\n",
      "4. summary: Enhance User Interface with Filtering and Sorting Options\n",
      "description: Add filtering and sorting capabilities to the transaction history display, enabling users to quickly find specific transactions or view them in chronological order.\n",
      "\n",
      "5. summary: Test Transaction History Functionality\n",
      "description: Write automated tests to ensure that the transaction history retrieval, display, and record keeping functionality work correctly and as expected.\n",
      "2025-11-11 12:22:15 - OllamaLLMStep.generate_tasks - INFO - Generation for row 1: 1. summary: Research and Identify Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that need to be supported in the logbook entries, including but not limited to alpha (Œ±), beta (Œ≤), gamma (Œ≥), delta (Œ¥), epsilon (Œµ), zeta (Œ∂), eta (Œ∑), theta (Œ∏), iota (Œπ), kappa (Œ∫), lambda (Œª), mu (Œº), nu (ŒΩ), xi (Œæ), omicron (Œø), pi (œÄ), rho (œÅ), sigma (œÉ), tau (œÑ), upsilon (œÖ), phi (œÜ), chi (œá), psi (œà), and omega (œâ).\n",
      "\n",
      "2. summary: Integrate Greek Symbol Input Field into Logbook Interface\n",
      "description: Modify the logbook entry form to include a field for inserting Greek symbols, ensuring that it is easily accessible and recognizable.\n",
      "\n",
      "3. summary: Develop Functionality to Convert Text Input to Greek Symbols\n",
      "description: Create a backend function or service that can convert text input (e.g., \"alpha\") into its corresponding Greek symbol (Œ±) when the user submits their logbook entry.\n",
      "\n",
      "4. summary: Test and Validate Greek Symbol Conversion\n",
      "description: Write unit tests and integration tests to ensure that the Greek symbol conversion functionality works correctly for all required symbols, including edge cases such as capitalization and punctuation.\n",
      "\n",
      "5. summary: Document Greek Symbol Input Guidelines for Researchers\n",
      "description: Create a user guide or documentation section that explains how researchers can use the new Greek symbol input feature in their logbook entries, including any specific formatting requirements or limitations.\n",
      "Processing generate_tasks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:25<00:12, 12.77s/it]2025-11-11 12:22:27 - OllamaLLMStep.generate_tasks - INFO - Generation for row 2: 1. summary: Define Embargo Release Date Logic\n",
      "description: Identify the current logic for lifting embargoes in the repository and document it, including any relevant database tables or fields involved.\n",
      "\n",
      "2. summary: Update Database Schema to Support Embargo Release Dates\n",
      "description: Modify the database schema to include a new field or table that stores the embargo release date for each item, ensuring that this information is persisted across system restarts.\n",
      "\n",
      "3. summary: Implement Automatic Embargo Lift on Release Date\n",
      "description: Write and integrate code that checks for upcoming embargo releases on the specified date and automatically lifts embargoes on the corresponding items in the repository.\n",
      "\n",
      "4. summary: Configure Access Controls Based on Item Configuration\n",
      "description: Develop a process to retrieve and apply access controls from the item's configuration, ensuring that these settings are correctly applied when an item is released from embargo.\n",
      "\n",
      "5. summary: Test Embargo Release Date Logic and Access Control Application\n",
      "description: Write comprehensive test cases to verify that the new embargo release date logic functions as expected, including successful lifting of embargoes and application of access controls based on item configuration.\n",
      "\n",
      "6. summary: Document Changes and Update User Guides\n",
      "description: Record all changes made to support this feature in the system documentation and update relevant user guides to reflect the new functionality, ensuring that users are aware of how to utilize the updated embargo release date logic and associated access control settings.\n",
      "Processing generate_tasks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:37<00:00, 12.43s/it]\n",
      "2025-11-11 12:22:27 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO -   ‚úì Complete (3 rows, 3 columns)\n",
      "2025-11-11 12:22:27 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Executing step: validate_tasks\n",
      "Validating validate_tasks:   0%|          | 0/3 [00:00<?, ?it/s]2025-11-11 12:22:46 - OllamaJudgeStep.validate_tasks - INFO - Validaci√≥n para fila 0: aprobado=False, total=41.0\n",
      "Validating validate_tasks:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:18<00:37, 18.89s/it]2025-11-11 12:23:08 - OllamaJudgeStep.validate_tasks - INFO - Validaci√≥n para fila 1: aprobado=False, total=44\n",
      "Validating validate_tasks:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:40<00:20, 20.72s/it]2025-11-11 12:23:28 - OllamaJudgeStep.validate_tasks - INFO - Validaci√≥n para fila 2: aprobado=True, total=44\n",
      "Validating validate_tasks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [01:01<00:00, 20.54s/it]\n",
      "2025-11-11 12:23:28 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO -   ‚úì Complete (3 rows, 13 columns)\n",
      "2025-11-11 12:23:28 - SimplePipeline.salony-tasks-pipeline-with-judge - INFO - Pipeline execution complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Guardando resultados...\n",
      "   ‚úì CSV guardado: salony_tasks_with_validation.csv\n",
      "   ‚úì 3 historias procesadas\n",
      "\n",
      "üìä Estad√≠sticas de validaci√≥n:\n",
      "   ‚úÖ Aprobadas: 1/3 (33.3%)\n",
      "   ‚ùå Rechazadas: 2/3 (66.7%)\n",
      "   üìà Puntuaci√≥n promedio: 43.0/50\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "üìã Ejemplo de resultado (primeras 2 filas):\n",
      "\n",
      "üîπ Historia #0:\n",
      "   Input: As a user, I want to be able to check transaction history and keep a record of it, so that I can go ...\n",
      "   Tasks: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch transaction history data from the database, including date...\n",
      "   Validaci√≥n: ‚ùå RECHAZADO (Score: 41.0/50)\n",
      "\n",
      "üîπ Historia #1:\n",
      "   Input: As a researcher, I want to have the ability to insert Greek symbols into my logbook entries....\n",
      "   Tasks: 1. summary: Research and Identify Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that need to be supported in the logbook en...\n",
      "   Validaci√≥n: ‚ùå RECHAZADO (Score: 44.0/50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Pipeline completo con validaci√≥n LLM juez\n",
    "result_df = run_salony_pipeline(\n",
    "    output_csv=\"salony_tasks_with_validation.csv\",\n",
    "    model_name=\"llama3.1:8b\",\n",
    "    judge_model_name=\"llama3.1:8b\", \n",
    "    batch_size=2,\n",
    "    temperature=0.3,\n",
    "    num_predict=1000,\n",
    "    sample_size=3,\n",
    "    use_judge=True,\n",
    "    judge_threshold=35.0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
