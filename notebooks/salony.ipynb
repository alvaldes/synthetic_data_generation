{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e8be84",
   "metadata": {},
   "source": [
    "Este pipeline toma historias de usuario del dataset salony_train.csv y las descompone\n",
    "en tareas de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffec7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "from simple_pipeline import SimplePipeline\n",
    "from simple_pipeline.steps import LoadDataFrame, OllamaLLMStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed41e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_generation_prompt(row: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Crea el prompt para generar tareas a partir de una historia de usuario del dataset Salony.\n",
    "    \n",
    "    Args:\n",
    "        row: Fila del DataFrame con la columna 'input' que contiene la historia\n",
    "    \n",
    "    Returns:\n",
    "        Prompt formateado\n",
    "    \"\"\"\n",
    "    user_story = row['input'].strip()\n",
    "    \n",
    "    prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides a user story.\n",
    "\n",
    "Write a response that appropriately completes the request.\n",
    "\n",
    "\n",
    "Instruction:\n",
    "\n",
    "Break this user story into smaller development tasks to help the developers implement it efficiently. You can divide this user story into as many tasks as needed, depending on its complexity. Each task must be unique, actionable, and non-overlapping.\n",
    "\n",
    "Use the following format for the response:\n",
    "\n",
    "1. summary: ‚Äπtask summary 1‚Ä∫\n",
    "description: ‚Äπtask description 1‚Ä∫\n",
    "2. summary: ‚Äπtask summary 2‚Ä∫\n",
    "description: ‚Äπtask description 2‚Ä∫\n",
    "\n",
    "N. summary: ‚Äπtask summary N‚Ä∫\n",
    "description: ‚Äπtask description N‚Ä∫\n",
    "\n",
    "\n",
    "Input:\n",
    "\n",
    "{user_story}\n",
    "\n",
    "\n",
    "Response:\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d27a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_salony_pipeline(\n",
    "    output_csv: str,\n",
    "    model_name: str = \"llama3.1:8b\",\n",
    "    batch_size: int = 2,\n",
    "    temperature: float = 0.3,\n",
    "    num_predict: int = 1000,\n",
    "    sample_size: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline de generaci√≥n de tareas para historias de usuario Salony.\n",
    "    \n",
    "    Args:\n",
    "        output_csv: Ruta donde guardar el resultado\n",
    "        model_name: Modelo de Ollama a usar\n",
    "        batch_size: N√∫mero de historias a procesar simult√°neamente\n",
    "        temperature: Temperatura para generaci√≥n\n",
    "        num_predict: Tokens m√°ximos a generar\n",
    "        sample_size: Si se especifica, procesa solo N historias (para pruebas)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üöÄ SALONY USER STORIES TO TASKS PIPELINE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Cargar datos - Usar ruta relativa desde el notebook\n",
    "    input_csv = Path(\"../data/salony_train.csv\")\n",
    "    print(f\"üì• Cargando datos desde: {input_csv}\")\n",
    "    \n",
    "    if not input_csv.exists():\n",
    "        raise FileNotFoundError(f\"No se encontr√≥ el archivo: {input_csv}\")\n",
    "    \n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Eliminar la primera columna si es un √≠ndice\n",
    "    if df.columns[0] == 'Unnamed: 0' or df.columns[0] == '':\n",
    "        df = df.iloc[:, 1:]\n",
    "    \n",
    "    print(f\"   ‚úì {len(df)} historias cargadas\")\n",
    "    \n",
    "    # Verificar columna 'input'\n",
    "    if 'input' not in df.columns:\n",
    "        raise ValueError(\"El CSV debe tener una columna 'input' con las historias de usuario\")\n",
    "    \n",
    "    # Aplicar sampling si se solicita\n",
    "    if sample_size:\n",
    "        df = df.head(sample_size)\n",
    "        print(f\"   ‚ÑπÔ∏è  Procesando solo {sample_size} historias (modo muestra)\")\n",
    "    \n",
    "    # Limpiar datos\n",
    "    df = df.dropna(subset=['input'])\n",
    "    df['input'] = df['input'].str.strip()\n",
    "    \n",
    "    # Crear pipeline\n",
    "    print(f\"\\n‚öôÔ∏è Configurando pipeline:\")\n",
    "    print(f\"   Modelo: {model_name}\")\n",
    "    print(f\"   Batch size: {batch_size}\")\n",
    "    print(f\"   Temperature: {temperature}\")\n",
    "    print(f\"   Historias a procesar: {len(df)}\")\n",
    "    \n",
    "    pipeline = SimplePipeline(\n",
    "        name=\"salony-tasks-pipeline\",\n",
    "        description=\"Pipeline para generar tareas de desarrollo del dataset Salony\"\n",
    "    )\n",
    "    \n",
    "    pipeline.add_step(\n",
    "        LoadDataFrame(name=\"load\", df=df)\n",
    "    )\n",
    "    \n",
    "    pipeline.add_step(\n",
    "        OllamaLLMStep(\n",
    "            name=\"generate_tasks\",\n",
    "            model_name=model_name,\n",
    "            prompt_column=\"input\",\n",
    "            output_column=\"tasks\",\n",
    "            prompt_template=create_task_generation_prompt,\n",
    "            system_prompt=\"You are an expert software development lead who excels at breaking down user stories into clear, actionable development tasks.\",\n",
    "            batch_size=batch_size,\n",
    "            generation_kwargs={\n",
    "                \"temperature\": temperature,\n",
    "                \"num_predict\": num_predict\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Ejecutar\n",
    "    print(f\"\\nüîÑ Procesando historias...\\n\")\n",
    "    result_df = pipeline.run(use_cache=False)\n",
    "    \n",
    "    # Guardar\n",
    "    print(f\"\\nüíæ Guardando resultados...\")\n",
    "    result_df.to_csv(output_csv, index=False)\n",
    "    print(f\"   ‚úì CSV guardado: {output_csv}\")\n",
    "    print(f\"   ‚úì {len(result_df)} historias procesadas\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Mostrar ejemplo\n",
    "    print(\"üìã Ejemplo de resultado (primeras 3 filas):\\n\")\n",
    "    for idx, row in result_df.head(3).iterrows():\n",
    "        print(f\"üîπ Historia #{idx}:\")\n",
    "        print(f\"   Input: {row['input'][:100]}...\")\n",
    "        if 'tasks' in row and pd.notna(row['tasks']):\n",
    "            print(f\"   Tasks: {row['tasks'][:200]}...\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d16e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Added step: load\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Added step: generate_tasks\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Starting pipeline: salony-tasks-pipeline\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Number of steps: 2\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Executing generator step: load\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Added step: generate_tasks\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Starting pipeline: salony-tasks-pipeline\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Number of steps: 2\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Executing generator step: load\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Executing step: generate_tasks\n",
      "2025-10-20 17:13:55 - SimplePipeline.salony-tasks-pipeline - INFO - Executing step: generate_tasks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ SALONY USER STORIES TO TASKS PIPELINE\n",
      "================================================================================\n",
      "\n",
      "üì• Cargando datos desde: ../data/salony_train.csv\n",
      "   ‚úì 1999 historias cargadas\n",
      "   ‚ÑπÔ∏è  Procesando solo 5 historias (modo muestra)\n",
      "\n",
      "‚öôÔ∏è Configurando pipeline:\n",
      "   Modelo: llama3.1:8b\n",
      "   Batch size: 2\n",
      "   Temperature: 0.3\n",
      "   Historias a procesar: 5\n",
      "\n",
      "üîÑ Procesando historias...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing generate_tasks:   0%|          | 0/5 [00:00<?, ?it/s]2025-10-20 17:14:21 - OllamaLLMStep.generate_tasks - INFO - Generation for row 0: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch the user's transaction history from the database, including relevant details such as date, amount, and description.\n",
      "\n",
      "2. summary: Display Transaction History on User Interface\n",
      "description: Create a user interface component (e.g., table or chart) to display the retrieved transaction history data in a readable format, allowing users to easily navigate through their past transactions.\n",
      "\n",
      "3. summary: Implement Record-Keeping Functionality\n",
      "description: Develop a feature that enables users to mark specific transactions as \"recorded\" or \"saved,\" allowing them to quickly identify and access important transactions when needed.\n",
      "\n",
      "4. summary: Enhance Search and Filtering Capabilities\n",
      "description: Add search functionality to the transaction history display, enabling users to quickly find specific transactions based on date, amount, description, or other relevant criteria.\n",
      "\n",
      "5. summary: Validate Transaction History Data\n",
      "description: Implement data validation checks to ensure that the retrieved transaction history is accurate and up-to-date, preventing any potential errors or inconsistencies.\n",
      "2025-10-20 17:14:21 - OllamaLLMStep.generate_tasks - INFO - Generation for row 0: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch the user's transaction history from the database, including relevant details such as date, amount, and description.\n",
      "\n",
      "2. summary: Display Transaction History on User Interface\n",
      "description: Create a user interface component (e.g., table or chart) to display the retrieved transaction history data in a readable format, allowing users to easily navigate through their past transactions.\n",
      "\n",
      "3. summary: Implement Record-Keeping Functionality\n",
      "description: Develop a feature that enables users to mark specific transactions as \"recorded\" or \"saved,\" allowing them to quickly identify and access important transactions when needed.\n",
      "\n",
      "4. summary: Enhance Search and Filtering Capabilities\n",
      "description: Add search functionality to the transaction history display, enabling users to quickly find specific transactions based on date, amount, description, or other relevant criteria.\n",
      "\n",
      "5. summary: Validate Transaction History Data\n",
      "description: Implement data validation checks to ensure that the retrieved transaction history is accurate and up-to-date, preventing any potential errors or inconsistencies.\n",
      "2025-10-20 17:14:37 - OllamaLLMStep.generate_tasks - INFO - Generation for row 1: 1. summary: Research and Document Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that will be supported in the logbook entries, document their Unicode values, and create a reference guide for future development.\n",
      "\n",
      "2. summary: Integrate Greek Symbol Keyboard Shortcuts\n",
      "description: Develop keyboard shortcuts or hotkeys to enable easy insertion of Greek symbols into logbook entries, ensuring compatibility with various input devices (e.g., keyboard, mouse).\n",
      "\n",
      "3. summary: Implement Greek Symbol Insertion Functionality\n",
      "description: Create a user interface component (e.g., button, dropdown menu) that allows researchers to insert Greek symbols directly into their logbook entries.\n",
      "\n",
      "4. summary: Ensure Compatibility with Existing Logbook Entry Format\n",
      "description: Modify the existing logbook entry format to accommodate the insertion of Greek symbols without disrupting the current data structure or formatting.\n",
      "\n",
      "5. summary: Test and Validate Greek Symbol Insertion Functionality\n",
      "description: Conduct thorough testing to ensure that Greek symbols can be inserted correctly into logbook entries, including edge cases such as symbol combinations and formatting.\n",
      "\n",
      "6. summary: Document User Interface Changes and Keyboard Shortcuts\n",
      "description: Update the user documentation to reflect changes made to the user interface and keyboard shortcuts for inserting Greek symbols, ensuring researchers are aware of these new features.\n",
      "2025-10-20 17:14:37 - OllamaLLMStep.generate_tasks - INFO - Generation for row 1: 1. summary: Research and Document Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that will be supported in the logbook entries, document their Unicode values, and create a reference guide for future development.\n",
      "\n",
      "2. summary: Integrate Greek Symbol Keyboard Shortcuts\n",
      "description: Develop keyboard shortcuts or hotkeys to enable easy insertion of Greek symbols into logbook entries, ensuring compatibility with various input devices (e.g., keyboard, mouse).\n",
      "\n",
      "3. summary: Implement Greek Symbol Insertion Functionality\n",
      "description: Create a user interface component (e.g., button, dropdown menu) that allows researchers to insert Greek symbols directly into their logbook entries.\n",
      "\n",
      "4. summary: Ensure Compatibility with Existing Logbook Entry Format\n",
      "description: Modify the existing logbook entry format to accommodate the insertion of Greek symbols without disrupting the current data structure or formatting.\n",
      "\n",
      "5. summary: Test and Validate Greek Symbol Insertion Functionality\n",
      "description: Conduct thorough testing to ensure that Greek symbols can be inserted correctly into logbook entries, including edge cases such as symbol combinations and formatting.\n",
      "\n",
      "6. summary: Document User Interface Changes and Keyboard Shortcuts\n",
      "description: Update the user documentation to reflect changes made to the user interface and keyboard shortcuts for inserting Greek symbols, ensuring researchers are aware of these new features.\n",
      "Processing generate_tasks:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:42<01:03, 21.27s/it]2025-10-20 17:14:52 - OllamaLLMStep.generate_tasks - INFO - Generation for row 2: 1. summary: Extract Embargo Release Date from Repository Configuration\n",
      "description: Identify and extract the embargo release dates currently stored in the repository configuration, ensuring that these dates are accurately recorded and accessible for future reference.\n",
      "\n",
      "2. summary: Develop Embargo Lift Functionality\n",
      "description: Implement a function within the repository system to automatically lift embargoes on the specified release date, allowing users to access previously restricted content without manual intervention.\n",
      "\n",
      "3. summary: Configure Access Controls Based on Item Configuration\n",
      "description: Integrate with the item configuration settings to determine the appropriate access controls for each item, ensuring that access is granted or denied based on the configured permissions and settings.\n",
      "\n",
      "4. summary: Test Embargo Lift Functionality\n",
      "description: Develop comprehensive test cases to validate the functionality of the embargo lift feature, ensuring it operates as intended across various scenarios and edge cases.\n",
      "\n",
      "5. summary: Document Changes and Update User Guides\n",
      "description: Update documentation and user guides to reflect the new embargo lift functionality, providing clear instructions for DigitalRecords Archivists on how to utilize this feature effectively.\n",
      "2025-10-20 17:14:52 - OllamaLLMStep.generate_tasks - INFO - Generation for row 2: 1. summary: Extract Embargo Release Date from Repository Configuration\n",
      "description: Identify and extract the embargo release dates currently stored in the repository configuration, ensuring that these dates are accurately recorded and accessible for future reference.\n",
      "\n",
      "2. summary: Develop Embargo Lift Functionality\n",
      "description: Implement a function within the repository system to automatically lift embargoes on the specified release date, allowing users to access previously restricted content without manual intervention.\n",
      "\n",
      "3. summary: Configure Access Controls Based on Item Configuration\n",
      "description: Integrate with the item configuration settings to determine the appropriate access controls for each item, ensuring that access is granted or denied based on the configured permissions and settings.\n",
      "\n",
      "4. summary: Test Embargo Lift Functionality\n",
      "description: Develop comprehensive test cases to validate the functionality of the embargo lift feature, ensuring it operates as intended across various scenarios and edge cases.\n",
      "\n",
      "5. summary: Document Changes and Update User Guides\n",
      "description: Update documentation and user guides to reflect the new embargo lift functionality, providing clear instructions for DigitalRecords Archivists on how to utilize this feature effectively.\n",
      "2025-10-20 17:15:05 - OllamaLLMStep.generate_tasks - INFO - Generation for row 3: 1. summary: Validate Dataset Creation Logic\n",
      "description: Implement a function that checks the status of each dataset creation attempt during application creation and returns an error if any fail.\n",
      "\n",
      "2. summary: Identify Datasets for Application Creation\n",
      "description: Determine which datasets are required for application creation and ensure they are properly configured in the system.\n",
      "\n",
      "3. summary: Create Dataset Creation Functionality\n",
      "description: Develop a function that creates new datasets for the application, including handling database connections and schema setup.\n",
      "\n",
      "4. summary: Integrate Dataset Validation with Application Creation Process\n",
      "description: Modify the application creation process to call the dataset validation function and return an error if any dataset creation fails.\n",
      "\n",
      "5. summary: Test Dataset Creation Failure Scenarios\n",
      "description: Develop test cases that simulate dataset creation failures during application creation and verify that the system returns an error as expected.\n",
      "\n",
      "6. summary: Document Dataset Creation Failure Logic\n",
      "description: Update documentation to reflect the new logic for handling dataset creation failures during application creation.\n",
      "Processing generate_tasks:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [01:09<00:16, 16.76s/it]2025-10-20 17:15:05 - OllamaLLMStep.generate_tasks - INFO - Generation for row 3: 1. summary: Validate Dataset Creation Logic\n",
      "description: Implement a function that checks the status of each dataset creation attempt during application creation and returns an error if any fail.\n",
      "\n",
      "2. summary: Identify Datasets for Application Creation\n",
      "description: Determine which datasets are required for application creation and ensure they are properly configured in the system.\n",
      "\n",
      "3. summary: Create Dataset Creation Functionality\n",
      "description: Develop a function that creates new datasets for the application, including handling database connections and schema setup.\n",
      "\n",
      "4. summary: Integrate Dataset Validation with Application Creation Process\n",
      "description: Modify the application creation process to call the dataset validation function and return an error if any dataset creation fails.\n",
      "\n",
      "5. summary: Test Dataset Creation Failure Scenarios\n",
      "description: Develop test cases that simulate dataset creation failures during application creation and verify that the system returns an error as expected.\n",
      "\n",
      "6. summary: Document Dataset Creation Failure Logic\n",
      "description: Update documentation to reflect the new logic for handling dataset creation failures during application creation.\n",
      "Processing generate_tasks:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [01:09<00:16, 16.76s/it]2025-10-20 17:15:19 - OllamaLLMStep.generate_tasks - INFO - Generation for row 4: 1. summary: Extract Derivation Logic Requirements\n",
      "description: Identify the current derivation logic requirements in the system and document them for reference.\n",
      "\n",
      "2. summary: Add New Case Patterns (00*****)\n",
      "description: Update the derivation logic to include a new case pattern for '00*****', ensuring that it is correctly identified and processed by the system.\n",
      "\n",
      "3. summary: Implement PPoPCode Handling\n",
      "description: Develop and integrate the necessary code to handle the 'PPoPCode' field, specifically for the '00FORGN' cases, including any required data mapping or validation.\n",
      "\n",
      "4. summary: Test New Derivation Logic\n",
      "description: Write automated tests to verify that the updated derivation logic correctly handles both new case patterns (00*****) and PPoPCode fields ('00FORGN') without introducing errors or inconsistencies in existing logic.\n",
      "\n",
      "5. summary: Review and Refactor Existing Code\n",
      "description: Conduct a thorough review of the modified code, ensuring it adheres to coding standards and best practices, and refactor if necessary for improved maintainability and performance.\n",
      "Processing generate_tasks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:23<00:00, 16.74s/it]2025-10-20 17:15:19 - OllamaLLMStep.generate_tasks - INFO - Generation for row 4: 1. summary: Extract Derivation Logic Requirements\n",
      "description: Identify the current derivation logic requirements in the system and document them for reference.\n",
      "\n",
      "2. summary: Add New Case Patterns (00*****)\n",
      "description: Update the derivation logic to include a new case pattern for '00*****', ensuring that it is correctly identified and processed by the system.\n",
      "\n",
      "3. summary: Implement PPoPCode Handling\n",
      "description: Develop and integrate the necessary code to handle the 'PPoPCode' field, specifically for the '00FORGN' cases, including any required data mapping or validation.\n",
      "\n",
      "4. summary: Test New Derivation Logic\n",
      "description: Write automated tests to verify that the updated derivation logic correctly handles both new case patterns (00*****) and PPoPCode fields ('00FORGN') without introducing errors or inconsistencies in existing logic.\n",
      "\n",
      "5. summary: Review and Refactor Existing Code\n",
      "description: Conduct a thorough review of the modified code, ensuring it adheres to coding standards and best practices, and refactor if necessary for improved maintainability and performance.\n",
      "Processing generate_tasks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:23<00:00, 16.74s/it]\n",
      "2025-10-20 17:15:19 - SimplePipeline.salony-tasks-pipeline - INFO -   ‚úì Complete (5 rows, 3 columns)\n",
      "2025-10-20 17:15:19 - SimplePipeline.salony-tasks-pipeline - INFO - Pipeline execution complete!\n",
      "\n",
      "2025-10-20 17:15:19 - SimplePipeline.salony-tasks-pipeline - INFO -   ‚úì Complete (5 rows, 3 columns)\n",
      "2025-10-20 17:15:19 - SimplePipeline.salony-tasks-pipeline - INFO - Pipeline execution complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Guardando resultados...\n",
      "   ‚úì CSV guardado: salony_tasks_output.csv\n",
      "   ‚úì 5 historias procesadas\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "üìã Ejemplo de resultado (primeras 3 filas):\n",
      "\n",
      "üîπ Historia #0:\n",
      "   Input: As a user, I want to be able to check transaction history and keep a record of it, so that I can go ...\n",
      "   Tasks: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch the user's transaction history from the database, including relevant details such as date, amount, and descr...\n",
      "\n",
      "üîπ Historia #1:\n",
      "   Input: As a researcher, I want to have the ability to insert Greek symbols into my logbook entries....\n",
      "   Tasks: 1. summary: Research and Document Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that will be supported in the logbook entries, document their Unicode values, and create a re...\n",
      "\n",
      "üîπ Historia #2:\n",
      "   Input: As a DigitalRecords Archivist, I want to have the repository to lift embargoes on the release date a...\n",
      "   Tasks: 1. summary: Extract Embargo Release Date from Repository Configuration\n",
      "description: Identify and extract the embargo release dates currently stored in the repository configuration, ensuring that these...\n",
      "\n",
      "   ‚úì CSV guardado: salony_tasks_output.csv\n",
      "   ‚úì 5 historias procesadas\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "üìã Ejemplo de resultado (primeras 3 filas):\n",
      "\n",
      "üîπ Historia #0:\n",
      "   Input: As a user, I want to be able to check transaction history and keep a record of it, so that I can go ...\n",
      "   Tasks: 1. summary: Retrieve Transaction History Data\n",
      "description: Develop an API endpoint to fetch the user's transaction history from the database, including relevant details such as date, amount, and descr...\n",
      "\n",
      "üîπ Historia #1:\n",
      "   Input: As a researcher, I want to have the ability to insert Greek symbols into my logbook entries....\n",
      "   Tasks: 1. summary: Research and Document Required Greek Symbols\n",
      "description: Identify all necessary Greek symbols that will be supported in the logbook entries, document their Unicode values, and create a re...\n",
      "\n",
      "üîπ Historia #2:\n",
      "   Input: As a DigitalRecords Archivist, I want to have the repository to lift embargoes on the release date a...\n",
      "   Tasks: 1. summary: Extract Embargo Release Date from Repository Configuration\n",
      "description: Identify and extract the embargo release dates currently stored in the repository configuration, ensuring that these...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_salony_pipeline(\n",
    "            output_csv=\"salony_tasks_output.csv\",\n",
    "            model_name=\"llama3.1:8b\",\n",
    "            batch_size=2,\n",
    "            temperature=0.3,\n",
    "            num_predict=1000,\n",
    "            sample_size=5\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
